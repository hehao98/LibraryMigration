{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-scroll",
   "metadata": {},
   "source": [
    "# Predictive Modeling for Library Migration\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "* H1: If many other projects have removed a library, it will be more likely for a project to migrate away from this library\n",
    "* H2: If many other projects have migrated from a library, it will be more likely for a project to migrate away from this library\n",
    "* H3: If the use of a library do not align well with current best practices, it will more likely for a project to migrate away from this library\n",
    "* H4: If a project have simultaneous use of same-domain libraries, it will be more likely to consolidate its usage to a single library\n",
    "* H5: A project is more likely to use a library that its upstream projects are already using\n",
    "* H6: If a library is not actively maintained, it will be more likely for a project to migrate away from this library\n",
    "* H7: If a library has unpatched security vulnerabilities, it will be more likely for a project to migrate away from this library\n",
    "* H8: If a library has an unusual license, it will be more likely for a project to migrate away from this library\n",
    "\n",
    "## Model\n",
    "\n",
    "首先，我们确立一组感兴趣的库集合$L$（$L$可能是若干个同一领域的库）。我们对这些库在大规模的项目集合$\\mathcal{P}$上提取所有的依赖项变更\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta L   &= \\{\\langle t,p,c,f,l^-,l^+,v^-,v^+ \\rangle\\}, p\\in \\mathcal{P}, x \\in \\Delta L \\Rightarrow x.l^- \\in L \\lor x.l^+ \\in L\\\\\n",
    "\\Delta L^+ &= \\{x | x \\in \\Delta L \\land x.l^+ \\in L \\land x.l^- = \\emptyset \\}\\\\\n",
    "\\Delta L^- &= \\{x | x \\in \\Delta L \\land x.l^- \\in L \\land x.l^+ = \\emptyset\\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "其中，$t$是时间，$c$是Commit，$f$是被修改的依赖配置文件。\n",
    "\n",
    "我们使用逻辑回归模型来拟合一个函数$f$，满足\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "f(x) = 1, x \\in \\Delta L^+ \\\\\n",
    "f(x) = 0, x \\in \\Delta L^-\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "对每个$x \\in \\Delta L$，定义其被添加或被删除的库为$l$，计算如下特征\n",
    "\n",
    "1. 项目做出变更的时间$t$减去$l$最近的上一次发布的时间。（刻画库是否正在被维护，验证H6）\n",
    "2. 项目做出变更的时间$t$减去$l$的第一次发布的时间。（刻画库的老旧程度，验证H6）\n",
    "3. 项目做出变更时，$l$能够查询到的安全漏洞的数量。（刻画库的安全漏洞情况，验证H7）\n",
    "4. $l$的许可证情况，按$L$集合里的许可证数量进行one-hot encoding。（验证H8）\n",
    "5. 项目做出变更时，项目的间接依赖里是否已经包含$l$。（验证H5）\n",
    "6. 项目做出变更时，项目的其他依赖配置文件里是否已经声明了$l$。(验证H4）\n",
    "7. 项目做出变更时，$l$在$\\mathcal{P}$中的全局留存率（1 - 被删除的次数 / 被添加的次数）。（验证H1）\n",
    "8. 项目做出变更时，$l$在已确认迁移中的流入比率（迁移图上入度 / 出度）。（验证H2）\n",
    "9. 项目做出变更时，$l$与剩下所有依赖的Pointwise Mutual Information (PMI)均值\n",
    "    $$\n",
    "    \\frac{1}{|x.f|}\\sum_{l'\\in x.f} \\log \\frac{p(l,l')}{p(l)p(l')}\n",
    "    $$\n",
    "    公式中概率使用$\\mathcal{P}$中所有依赖配置文件来估计。（验证H3）\n",
    "\n",
    "备注：为了计算上述指标，需要额外研究一下如何获取安全漏洞数据。可能考虑：GitHub Advisories，或参考已有研究。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-racing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Snailclimb/JavaGuide' 'e8aeaef43cbfb2b8a9b71c7b7f462c48b4adb9a6'\n",
      " 'docs/dataStructures-algorithms/source code/securityAlgorithm/pom.xml'\n",
      " 'add' nan 'junit:junit' nan '4.12' '2019-03-25 09:19:36+00:00']\n",
      "-0.8809776833156217\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pymongo\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse as dateParser\n",
    "import datautil\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Set\n",
    "import csv\n",
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "from pathos.pools import ProcessPool\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "MONGO_URL = \"mongodb://127.0.0.1:27017\"\n",
    "db = pymongo.MongoClient(MONGO_URL, connect=False, maxPoolSize=200).migration_helper\n",
    "raw_db = pymongo.MongoClient(MONGO_URL, connect=False, maxPoolSize=200).libraries\n",
    "migration_commits = pd.read_csv('data/migration_changes_with_time.csv', dtype=object)\n",
    "migration_commits_values = migration_commits.values\n",
    "count = 0\n",
    "\n",
    "def get_migration_to_library(lib: str) -> pd.DataFrame:\n",
    "    # migration_commits = pd.read_csv('data/migration_changes.csv', dtype=object)\n",
    "    lib_required = migration_commits['lib2'].map(lambda x: x == lib)\n",
    "    type_required = migration_commits['type'].map(lambda x: x == 'add')\n",
    "    migration_to_commits = migration_commits[lib_required & type_required]\n",
    "    return migration_to_commits\n",
    "\n",
    "def get_migration_to_library_before(lib: str, datetime: datetime) -> pd.DataFrame:\n",
    "    # migration_commits = pd.read_csv('data/migration_changes_with_time.csv', dtype=object)\n",
    "    datetime = str(datetime)\n",
    "    migration_to_commits_before = migration_commits_values[(migration_commits_values[:, -1] < str(datetime)) & (migration_commits_values[:, 5] == lib) &( migration_commits_values[:, 3] == 'add')]\n",
    "    return len(migration_to_commits_before)\n",
    "\n",
    "def get_migration_to()->np.ndarray:\n",
    "    type_required = migration_commits['type'].map(lambda x: x == 'add')\n",
    "    migration_to_commits = migration_commits[type_required]\n",
    "    return migration_to_commits\n",
    "\n",
    "def get_migration_from()->np.ndarray:\n",
    "    type_required = migration_commits['type'].map(lambda x: x == 'rem')\n",
    "    migration_from_commits = migration_commits[type_required]\n",
    "    return migration_from_commits\n",
    "\n",
    "def get_migration_from_library(lib: str) -> pd.DataFrame:\n",
    "    type_required = migration_commits['type'].map(lambda x: x == 'rem')\n",
    "    lib_required = migration_commits['lib1'].map(lambda x: x == lib)\n",
    "    migration_from_commits = migration_commits[lib_required & type_required]\n",
    "    return migration_from_commits\n",
    "\n",
    "def get_migration_from_library_before(lib: str, datetime: datetime) -> pd.DataFrame:\n",
    "    datetime = str(datetime)\n",
    "    migration_from_commits_before = migration_commits_values[(migration_commits_values[:, -1] < str(datetime)) & (migration_commits_values[:, 4] == lib) &( migration_commits_values[:, 3] == 'rem')]\n",
    "    return len(migration_from_commits_before)\n",
    "\n",
    "\n",
    "def get_commit_time(commit: str) -> datetime:\n",
    "    c = db.wocCommit.find_one({\"_id\": commit})\n",
    "    if c is not None:\n",
    "        return c['timestamp'].replace(tzinfo=pytz.timezone('UTC'))\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_library_nearest_published_time(lib: str, commit_time: datetime) -> datetime:\n",
    "    raw_dbt = pymongo.MongoClient(MONGO_URL, connect=False, maxPoolSize=None).libraries\n",
    "    library_versions = list(raw_dbt.versions.find({\"Platform\": \"Maven\", \"Project Name\": lib}, sort=[\n",
    "                                            (\"Published Timestamp\", pymongo.DESCENDING)]))\n",
    "    for library_version in library_versions:\n",
    "        published_time = dateParser(library_version['Published Timestamp'])\n",
    "        if published_time < commit_time:\n",
    "            return published_time\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_library_first_published_time(lib: str) -> datetime:\n",
    "    return dateParser(list(raw_db.versions.find({\"Platform\": \"Maven\", \"Project Name\": lib}, sort=[\n",
    "        (\"Published Timestamp\", pymongo.ASCENDING)]))[0][\"Published Timestamp\"])\n",
    "\n",
    "\n",
    "def get_project_before_config_direct_dependency(commit: str, config_filename: str) -> List:\n",
    "    diffs = db.wocCommit.find_one({\"_id\": commit})['diffs']\n",
    "    pom_blob = None\n",
    "    for diff in diffs:\n",
    "        if diff['filename'] == config_filename:\n",
    "            pom_blob = diff['oldBlob']\n",
    "    if not pom_blob:\n",
    "        return None\n",
    "    else:\n",
    "        direct_dependencies = db.wocPomBlob.find_one({'_id': pom_blob})['dependencies']\n",
    "        return direct_dependencies\n",
    "\n",
    "\n",
    "def get_project_before_other_direct_dependency(project: str, commit: str, config_filename: str) -> pd.DataFrame:\n",
    "    commits = db.wocRepository.find_one({\"name\": project.replace(\"/\", \"_\")})['commits']\n",
    "    migration_time = get_commit_time(commit)\n",
    "    other_config_blobs = {}\n",
    "    dependencies = []\n",
    "    print(len(commits))\n",
    "    i = 0\n",
    "    for c in commits:\n",
    "        if (i % 100 == 0):\n",
    "            print(i)\n",
    "        i += 1\n",
    "        commit = db.wocCommit.find_one({\"_id\": c})\n",
    "        if commit is None:\n",
    "            continue\n",
    "        commit_time = commit['timestamp'].replace(tzinfo=pytz.timezone('UTC'))\n",
    "        if commit_time < migration_time:\n",
    "            diffs = commit['diffs']\n",
    "            for diff in diffs:\n",
    "                if re.search(r'pom.xml', diff['filename']) is not None and config_filename != diff['filename']:\n",
    "                    other_config_file = diff['filename']\n",
    "                    if diff['filename'] not in other_config_blobs.keys():\n",
    "                        other_config_blobs[other_config_file] = {\"timestamp\": commit_time, \"blob\": diff['newBlob']}\n",
    "                    else:\n",
    "                        if commit_time > other_config_blobs[other_config_file]['timestamp']:\n",
    "                            other_config_blobs[other_config_file]['timestamp'] = commit_time\n",
    "                            other_config_blobs[other_config_file]['blob'] = diff['newBlob']\n",
    "    for value in other_config_blobs.values():\n",
    "        if value['blob'] != \"\":\n",
    "            dependencies.extend(db.wocPomBlob.find_one({'_id': value['blob']})['dependencies'])\n",
    "    return pd.DataFrame(dependencies)\n",
    "\n",
    "\n",
    "def get_library_direct_dependency(groupId: str, artifactId: str, version: str) -> List[dict]:\n",
    "    dependencies = []\n",
    "    projectName = groupId + \":\" + artifactId\n",
    "    if version != \"\" and '$' not in version and '[' not in version:\n",
    "        results = list(db.lioProjectDependency.find(\n",
    "            {\"projectName\": projectName, \"versionNumber\": {'$regex' :f\"{version}.*\"}}, sort=[\n",
    "                (\"version\", pymongo.DESCENDING)]))        \n",
    "    else:\n",
    "        results = list(db.lioProjectDependency.find(\n",
    "            {\"projectName\": projectName}, sort=[\n",
    "                (\"version\", pymongo.DESCENDING)]))\n",
    "    if results:\n",
    "        versionNumber = results[0]['versionNumber']\n",
    "        results = list(db.libraryVersionToDependency.find(\n",
    "                {\"projectName\": projectName, \"versionNumber\": versionNumber}))\n",
    "        for result in results:\n",
    "            groupId, artifactId = result[\"projectName\"].split(\":\")\n",
    "            version = result[\"versionNumber\"]\n",
    "            dependencies.append({\"groupId\":groupId,\"artifactId\":artifactId, \"version\":version})\n",
    "    return dependencies\n",
    "    \n",
    "\n",
    "\n",
    "def get_project_before_config_all_dependencies(commit: str, config_filename: str) -> pd.DataFrame:\n",
    "    dependencies = []\n",
    "    temp_dependencies = get_project_before_config_direct_dependency(commit, config_filename)\n",
    "    while temp_dependencies:\n",
    "        now_dependency = temp_dependencies.pop(0)\n",
    "        if now_dependency in dependencies:\n",
    "            continue\n",
    "        else:\n",
    "            dependencies.append(now_dependency)\n",
    "        new_dependencies = get_library_direct_dependency(\n",
    "            now_dependency['groupId'], now_dependency['artifactId'], now_dependency['version'])\n",
    "        if new_dependencies:\n",
    "            temp_dependencies.extend(new_dependencies)\n",
    "            for d in new_dependencies:\n",
    "                if d not in dependencies:\n",
    "                    dependencies.append(d)\n",
    "    return pd.DataFrame(dependencies)\n",
    "\n",
    "\n",
    "def index_1(migration_change:np.ndarray, lib: str) -> int:\n",
    "    change_time = dateParser(migration_change[-1])\n",
    "    library_nearest_time = get_library_nearest_published_time(lib, change_time)\n",
    "    if library_nearest_time:\n",
    "        return (change_time - library_nearest_time).days\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def index_2(migration_change: np.ndarray, lib: str) -> int:\n",
    "    change_time = dateParser(migration_change[-1])\n",
    "    library_first_time = get_library_first_published_time(lib)\n",
    "    return (change_time - library_first_time).days\n",
    "\n",
    "def index_1_all(migration_change:np.ndarray) -> int:\n",
    "    if migration_change[3] == 'add':\n",
    "        lib = migration_change[5]\n",
    "    elif migration_change[4] == 'rem':\n",
    "        lib = migration_change[4]\n",
    "    else:\n",
    "        return np.nan\n",
    "    change_time = dateParser(migration_change[-1])\n",
    "    library_nearest_time = get_library_nearest_published_time(lib, change_time)\n",
    "    if library_nearest_time:\n",
    "        return (change_time - library_nearest_time).days\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def index_2_all(migration_change: np.ndarray) -> int:\n",
    "    if migration_change[3] == 'add':\n",
    "        lib = migration_change[5]\n",
    "    elif migration_change[4] == 'rem':\n",
    "        lib = migration_change[4]\n",
    "    else:\n",
    "        return np.nan\n",
    "    change_time = dateParser(migration_change[-1])\n",
    "    library_first_time = get_library_first_published_time(lib)\n",
    "    return (change_time - library_first_time).days\n",
    "\n",
    "\n",
    "def index_5(migration_change: np.ndarray, lib: str) -> int:\n",
    "    groupId, artifactId = lib.split(':')\n",
    "    all_dependencies = get_project_before_config_all_dependencies(\n",
    "        migration_change[2], migration_change[3])\n",
    "    if len(all_dependencies) == 0 or len(all_dependencies[(all_dependencies['groupId'] == groupId) & (all_dependencies['artifactId'] == artifactId)].index) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def index_6(migration_change: np.ndarray, lib: str) -> int:\n",
    "    groupId, artifactId = lib.split(':')\n",
    "    other_direct_dependencies = get_project_before_other_direct_dependency(migration_change[1],\n",
    "        migration_change[2], migration_change[3])\n",
    "    if len(other_direct_dependencies[(other_direct_dependencies['groupId'] == groupId) & (other_direct_dependencies['artifactId'] == artifactId)].index) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_library_retention_rate(migration_change:np.ndarray, lib: str) -> float:  # 7\n",
    "    # commit_time = get_commit_time(migration_change[2])\n",
    "    commit_time = migration_change[-1]\n",
    "    remove = get_migration_from_library_before(lib, commit_time)\n",
    "    add = get_migration_to_library_before(lib, commit_time)\n",
    "#     if add == 0:\n",
    "#         return float(\"-inf\")\n",
    "#     return 1 - remove / add\n",
    "    if add == 0 and remove == 0:\n",
    "        return 0\n",
    "    return add / (add + remove)\n",
    "\n",
    "\n",
    "def get_library_inflow_rate(migration_change:np.ndarray, lib: str) -> float:  # 8\n",
    "    dbt = pymongo.MongoClient(MONGO_URL, connect=False, maxPoolSize=200).migration_helper\n",
    "    commit_time = dateParser(migration_change[-1])\n",
    "    add = len(list(dbt.wocConfirmedMigration.find(\n",
    "        {\"toLib\": lib, \"startCommitTime\": {'$lt': commit_time}})))\n",
    "    remove = len(list(dbt.wocConfirmedMigration.find(\n",
    "        {\"fromLib\": lib, \"startCommitTime\": {'$lt': commit_time}})))\n",
    "    if add == 0 and remove == 0:\n",
    "        return 0\n",
    "    return (add - remove) / (add + remove)\n",
    "\n",
    "def get_library_retention_rate_all(migration_change:np.ndarray) -> float:  # 7\n",
    "    if migration_change[3] == 'add':\n",
    "        lib = migration_change[5]\n",
    "    elif migration_change[4] == 'rem':\n",
    "        lib = migration_change[4]\n",
    "    else:\n",
    "        return np.nan\n",
    "    commit_time = migration_change[-1]\n",
    "    remove = get_migration_from_library_before(lib, commit_time)\n",
    "    add = get_migration_to_library_before(lib, commit_time)\n",
    "#     if add == 0:\n",
    "#         return float(\"-inf\")\n",
    "#     return 1 - remove / add\n",
    "    if add == 0 and remove == 0:\n",
    "        return 0\n",
    "    return add / (add + remove)\n",
    "\n",
    "\n",
    "def get_library_inflow_rate_all(migration_change:np.ndarray) -> float:  # 8\n",
    "    dbt = pymongo.MongoClient(MONGO_URL, connect=False, maxPoolSize=None).migration_helper\n",
    "    if migration_change[3] == 'add':\n",
    "        lib = migration_change[5]\n",
    "    elif migration_change[4] == 'rem':\n",
    "        lib = migration_change[4]\n",
    "    else:\n",
    "        return np.nan\n",
    "    commit_time = dateParser(migration_change[-1])\n",
    "    add = len(list(dbt.wocConfirmedMigration.find(\n",
    "        {\"toLib\": lib, \"startCommitTime\": {'$lt': commit_time}})))\n",
    "    remove = len(list(dbt.wocConfirmedMigration.find(\n",
    "        {\"fromLib\": lib, \"startCommitTime\": {'$lt': commit_time}})))\n",
    "    if add == 0 and remove == 0:\n",
    "        return 0\n",
    "    return (add - remove) / (add + remove)\n",
    "\n",
    "def parallel(func, *args):\n",
    "    pool = ProcessPool(96)\n",
    "    try:\n",
    "        start = time.time()\n",
    "        # imap方法\n",
    "        with tqdm(total=len(args[0]), desc=\"计算进度\") as t:  # 进度条设置\n",
    "            r = []\n",
    "            for i in pool.imap(func, *args):\n",
    "                r.append(i)\n",
    "                t.set_postfix({'并行函数': func.__name__, \"计算花销\": \"%ds\" % (time.time() - start)})\n",
    "                t.update()\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        # 关闭池\n",
    "        pool.close()  # close the pool to any new jobs\n",
    "        pool.join()  # cleanup the closed worker processes\n",
    "        pool.clear()  # Remove server with matching state\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    #print(get_library_nearest_published_time(\"com.alibaba:fastjson\", get_commit_time(\"10052d468760f2f952064289719286d3ba608693\")))\n",
    "    # print(get_library_first_published_time(\"commons-codec:commons-codec\"))\n",
    "    # print(get_project_before_config_all_dependencies(\"7c65c5b167a85e28d21c58dc6c96c75bef04a444\",\n",
    "    #                                                  \"pom.xml\"))\n",
    "    # print(get_project_before_other_direct_dependency(\"Snailclimb/JavaGuide\", \"e8aeaef43cbfb2b8a9b71c7b7f462c48b4adb9a6\",\n",
    "    #                                                  \"docs/dataStructures-algorithms/source code/securityAlgorithm/pom.xml\"))\n",
    "    # print(get_library_direct_dependency(\"org.json\", \"json\", \"\"))\n",
    "    print(migration_commits_values[1])\n",
    "#     print(get_library_retention_rate(migration_commits.values[1], \"junit:junit\"))\n",
    "    print(get_library_inflow_rate(migration_commits_values[1], \"junit:junit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datautil\n",
    "import model\n",
    "import pandas as pd\n",
    "dep_change = datautil.select_dependency_changes_all()\n",
    "commit_time = []\n",
    "count = 0\n",
    "for data in dep_change.values:\n",
    "    count += 1\n",
    "    if count % 50000 == 0:\n",
    "        print(count)\n",
    "    commit_time.append(model.get_commit_time(data[2]))\n",
    "dep_change['commit_time'] = commit_time\n",
    "print(len(dep_change))\n",
    "print(dep_change.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "migration_commits = pd.read_csv('data/migration_changes_with_time.csv', dtype=object)\n",
    "print(migration_commits.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "instructional-faculty",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算进度: 100%|██████████| 3646/3646 [00:05<00:00, 607.71it/s, 并行函数=index_1, 计算花销=6s] \n",
      "计算进度: 100%|██████████| 3646/3646 [00:04<00:00, 886.90it/s, 并行函数=index_2, 计算花销=4s] \n",
      "计算进度: 100%|██████████| 3646/3646 [00:28<00:00, 127.47it/s, 并行函数=get_library_retention_rate, 计算花销=28s]\n",
      "计算进度: 100%|██████████| 3646/3646 [00:05<00:00, 611.24it/s, 并行函数=get_library_inflow_rate, 计算花销=5s] \n",
      "计算进度: 100%|██████████| 646/646 [00:01<00:00, 622.49it/s, 并行函数=index_1, 计算花销=1s] \n",
      "计算进度: 100%|██████████| 646/646 [00:00<00:00, 807.31it/s, 并行函数=index_2, 计算花销=0s] \n",
      "计算进度: 100%|██████████| 646/646 [00:05<00:00, 124.77it/s, 并行函数=get_library_retention_rate, 计算花销=5s]\n",
      "计算进度: 100%|██████████| 646/646 [00:01<00:00, 606.46it/s, 并行函数=get_library_inflow_rate, 计算花销=1s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算进度: 100%|██████████| 2908/2908 [00:04<00:00, 623.35it/s, 并行函数=index_1, 计算花销=4s] \n",
      "计算进度: 100%|██████████| 2908/2908 [00:03<00:00, 846.98it/s, 并行函数=index_2, 计算花销=3s] \n",
      "计算进度: 100%|██████████| 2908/2908 [00:22<00:00, 127.40it/s, 并行函数=get_library_retention_rate, 计算花销=22s]\n",
      "计算进度: 100%|██████████| 2908/2908 [00:04<00:00, 616.48it/s, 并行函数=get_library_inflow_rate, 计算花销=4s] \n",
      "计算进度: 100%|██████████| 234/234 [00:00<00:00, 576.69it/s, 并行函数=index_1, 计算花销=0s]\n",
      "计算进度: 100%|██████████| 234/234 [00:00<00:00, 622.39it/s, 并行函数=index_2, 计算花销=0s]\n",
      "计算进度: 100%|██████████| 234/234 [00:02<00:00, 111.96it/s, 并行函数=get_library_retention_rate, 计算花销=2s]\n",
      "计算进度: 100%|██████████| 234/234 [00:00<00:00, 656.43it/s, 并行函数=get_library_inflow_rate, 计算花销=0s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算进度: 100%|██████████| 6505/6505 [00:12<00:00, 520.27it/s, 并行函数=index_1, 计算花销=12s] \n",
      "计算进度: 100%|██████████| 6505/6505 [00:07<00:00, 862.30it/s, 并行函数=index_2, 计算花销=7s] \n",
      "计算进度: 100%|██████████| 6505/6505 [00:50<00:00, 127.98it/s, 并行函数=get_library_retention_rate, 计算花销=50s]\n",
      "计算进度: 100%|██████████| 6505/6505 [00:10<00:00, 613.92it/s, 并行函数=get_library_inflow_rate, 计算花销=10s] \n",
      "计算进度: 100%|██████████| 944/944 [00:01<00:00, 519.84it/s, 并行函数=index_1, 计算花销=1s] \n",
      "计算进度: 100%|██████████| 944/944 [00:01<00:00, 808.86it/s, 并行函数=index_2, 计算花销=1s] \n",
      "计算进度: 100%|██████████| 944/944 [00:07<00:00, 126.49it/s, 并行函数=get_library_retention_rate, 计算花销=7s]\n",
      "计算进度: 100%|██████████| 944/944 [00:01<00:00, 633.86it/s, 并行函数=get_library_inflow_rate, 计算花销=1s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算进度: 100%|██████████| 6034/6034 [00:10<00:00, 566.59it/s, 并行函数=index_1, 计算花销=10s] \n",
      "计算进度: 100%|██████████| 6034/6034 [00:07<00:00, 829.08it/s, 并行函数=index_2, 计算花销=7s] \n",
      "计算进度: 100%|██████████| 6034/6034 [00:47<00:00, 127.38it/s, 并行函数=get_library_retention_rate, 计算花销=47s]\n",
      "计算进度: 100%|██████████| 6034/6034 [00:09<00:00, 622.78it/s, 并行函数=get_library_inflow_rate, 计算花销=9s] \n",
      "计算进度: 100%|██████████| 1020/1020 [00:01<00:00, 574.36it/s, 并行函数=index_1, 计算花销=1s] \n",
      "计算进度: 100%|██████████| 1020/1020 [00:01<00:00, 782.99it/s, 并行函数=index_2, 计算花销=1s] \n",
      "计算进度: 100%|██████████| 1020/1020 [00:08<00:00, 126.46it/s, 并行函数=get_library_retention_rate, 计算花销=8s]\n",
      "计算进度: 100%|██████████| 1020/1020 [00:01<00:00, 615.35it/s, 并行函数=get_library_inflow_rate, 计算花销=1s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算进度: 100%|██████████| 4711/4711 [00:08<00:00, 578.10it/s, 并行函数=index_1, 计算花销=8s] \n",
      "计算进度: 100%|██████████| 4711/4711 [00:05<00:00, 835.49it/s, 并行函数=index_2, 计算花销=5s] \n",
      "计算进度: 100%|██████████| 4711/4711 [00:36<00:00, 127.80it/s, 并行函数=get_library_retention_rate, 计算花销=36s]\n",
      "计算进度: 100%|██████████| 4711/4711 [00:07<00:00, 622.83it/s, 并行函数=get_library_inflow_rate, 计算花销=7s] \n",
      "计算进度: 100%|██████████| 791/791 [00:01<00:00, 597.51it/s, 并行函数=index_1, 计算花销=1s] \n",
      "计算进度: 100%|██████████| 791/791 [00:00<00:00, 806.05it/s, 并行函数=index_2, 计算花销=0s] \n",
      "计算进度: 100%|██████████| 791/791 [00:06<00:00, 121.35it/s, 并行函数=get_library_retention_rate, 计算花销=6s]\n",
      "计算进度: 100%|██████████| 791/791 [00:01<00:00, 582.62it/s, 并行函数=get_library_inflow_rate, 计算花销=1s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算进度: 100%|██████████| 10445/10445 [00:17<00:00, 603.47it/s, 并行函数=index_1, 计算花销=17s] \n",
      "计算进度: 100%|██████████| 10445/10445 [00:12<00:00, 811.52it/s, 并行函数=index_2, 计算花销=12s] \n",
      "计算进度: 100%|██████████| 10445/10445 [01:21<00:00, 127.83it/s, 并行函数=get_library_retention_rate, 计算花销=81s]\n",
      "计算进度: 100%|██████████| 10445/10445 [00:15<00:00, 655.21it/s, 并行函数=get_library_inflow_rate, 计算花销=15s] \n",
      "计算进度: 100%|██████████| 1570/1570 [00:02<00:00, 566.90it/s, 并行函数=index_1, 计算花销=2s] \n",
      "计算进度: 100%|██████████| 1570/1570 [00:01<00:00, 852.81it/s, 并行函数=index_2, 计算花销=1s] \n",
      "计算进度: 100%|██████████| 1570/1570 [00:12<00:00, 124.84it/s, 并行函数=get_library_retention_rate, 计算花销=12s]\n",
      "计算进度: 100%|██████████| 1570/1570 [00:02<00:00, 624.71it/s, 并行函数=get_library_inflow_rate, 计算花销=2s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "libs = [\n",
    "    \"org.json:json\", \n",
    "    \"com.alibaba:fastjson\", \n",
    "    \"com.google.code.gson:gson\", \n",
    "    \"com.fasterxml.jackson.core:jackson-core\", \n",
    "    \"com.fasterxml.jackson.core:jackson-annotations\", \n",
    "    \"com.fasterxml.jackson.core:jackson-databind\"\n",
    "]\n",
    "index1 = np.array([])\n",
    "index2 = np.array([])\n",
    "index7 = np.array([])\n",
    "index8 = np.array([])\n",
    "f = np.array([])\n",
    "\n",
    "\n",
    "            \n",
    "for lib in libs:\n",
    "    migrations_to_lib = get_migration_to_library(lib).values\n",
    "    migrations_from_lib = get_migration_from_library(lib).values\n",
    "    print(len(migrations_to_lib) + len(migrations_from_lib))\n",
    "    \n",
    "    l1 = [lib] * len(migrations_to_lib)\n",
    "    index1 = np.append(index1, parallel(index_1, migrations_to_lib, l1))\n",
    "    index2 = np.append(index2, parallel(index_2, migrations_to_lib, l1))\n",
    "    index7 = np.append(index7, parallel(get_library_retention_rate, migrations_to_lib, l1))\n",
    "    index8 = np.append(index8, parallel(get_library_inflow_rate, migrations_to_lib, l1))\n",
    "    f = np.append(f,[1] * len(l1))\n",
    "\n",
    "    l2 = [lib] * len(migrations_from_lib)\n",
    "    index1 = np.append(index1, parallel(index_1, migrations_from_lib, l2))\n",
    "    index2 = np.append(index2, parallel(index_2, migrations_from_lib, l2))\n",
    "    index7 = np.append(index7, parallel(get_library_retention_rate, migrations_from_lib, l2))\n",
    "    index8 = np.append(index8, parallel(get_library_inflow_rate, migrations_from_lib, l2))\n",
    "    f = np.append(f,[0] * len(l2))  \n",
    "\n",
    "print(len(index1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算进度:   5%|▌         | 173127/3328884 [25:03<7:18:25, 119.96it/s, 并行函数=index_1_all, 计算花销=1503s]"
     ]
    }
   ],
   "source": [
    "index1 = np.array([])\n",
    "index2 = np.array([])\n",
    "index7 = np.array([])\n",
    "index8 = np.array([])\n",
    "f = np.array([])\n",
    "\n",
    "data = migration_commits_values\n",
    "index1 = np.append(index1, parallel(index_1_all, data))\n",
    "# index2 = np.append(index2, parallel(index_2_all, data))\n",
    "# index7 = np.append(index7, parallel(get_library_retention_rate_all, data))\n",
    "# index8 = np.append(index8, parallel(get_library_inflow_rate_all, data))\n",
    "# f = np.append(f,[0] * len(data))  \n",
    "migration_commits['index1'] = index1\n",
    "# migration_commits['index2'] = index2\n",
    "# migration_commits['index7'] = index7\n",
    "# migration_commits['index8'] = index8\n",
    "print(migration_commits.head(5))\n",
    "migration_commits.to_csv('data/migration_changes_with_index.csv', index=False)\n",
    "print(len(index1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "green-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "                      0                                         1  \\\n",
      "0  Snailclimb/JavaGuide  e8aeaef43cbfb2b8a9b71c7b7f462c48b4adb9a6   \n",
      "1  Snailclimb/JavaGuide  e8aeaef43cbfb2b8a9b71c7b7f462c48b4adb9a6   \n",
      "2  Snailclimb/JavaGuide  e8aeaef43cbfb2b8a9b71c7b7f462c48b4adb9a6   \n",
      "3  Snailclimb/JavaGuide  a17a2800c92f918842d26a9e9261ae0bba89286d   \n",
      "4  Snailclimb/JavaGuide  a17a2800c92f918842d26a9e9261ae0bba89286d   \n",
      "\n",
      "                                                   2    3    4  \\\n",
      "0  docs/dataStructures-algorithms/source code/sec...  add  NaN   \n",
      "1  docs/dataStructures-algorithms/source code/sec...  add  NaN   \n",
      "2  docs/dataStructures-algorithms/source code/sec...  add  NaN   \n",
      "3      数据结构与算法/source code/securityAlgorithm/pom.xml  add  NaN   \n",
      "4      数据结构与算法/source code/securityAlgorithm/pom.xml  add  NaN   \n",
      "\n",
      "                                 5    6      7                          8  \\\n",
      "0      commons-codec:commons-codec  NaN    1.8  2019-03-25 09:19:36+00:00   \n",
      "1                      junit:junit  NaN   4.12  2019-03-25 09:19:36+00:00   \n",
      "2  org.bouncycastle:bcprov-jdk15on  NaN   1.56  2019-03-25 09:19:36+00:00   \n",
      "3      commons-codec:commons-codec  NaN    1.8  2018-07-31 06:49:01+00:00   \n",
      "4                      junit:junit  NaN  3.8.1  2018-07-31 06:49:01+00:00   \n",
      "\n",
      "   index1  index2  \n",
      "0    44.0  4909.0  \n",
      "1    50.0  4983.0  \n",
      "2    42.0  2558.0  \n",
      "3   287.0  4671.0  \n",
      "4  1334.0  4746.0  \n"
     ]
    }
   ],
   "source": [
    "datas = pd.DataFrame(data)\n",
    "print(len(datas))\n",
    "datas['index1'] = index1\n",
    "datas['index2'] = index2\n",
    "print(datas.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "expensive-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                         nan\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Wed, 10 Feb 2021   Prob (F-statistic):                nan\n",
      "Time:                        13:41:59   Log-Likelihood:                    inf\n",
      "No. Observations:                 668   AIC:                              -inf\n",
      "Df Residuals:                     663   BIC:                              -inf\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const               0          0        nan        nan           0           0\n",
      "x1                  0          0        nan        nan           0           0\n",
      "x2                  0          0        nan        nan           0           0\n",
      "x3                  0          0        nan        nan           0           0\n",
      "x4                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     1883.893   Durbin-Watson:                     nan\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              250.500\n",
      "Skew:                           0.000   Prob(JB):                     4.02e-55\n",
      "Kurtosis:                       0.000   Cond. No.                     7.01e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.01e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1715: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1804: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return self.mse_model/self.mse_resid\n",
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:903: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/statsmodels/stats/stattools.py:50: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dw = np.sum(diff_resids**2, axis=axis) / np.sum(resids**2, axis=axis)\n",
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/statsmodels/stats/outliers_influence.py:693: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.resid / sigma / np.sqrt(1 - hii)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm # 最小二乘\n",
    "from statsmodels.stats.outliers_influence import summary_table # 获得汇总信息\n",
    "temp = np.c_[index1, index2, index7, index8, f]\n",
    "temp = temp[(temp[:, 0] > 0)]\n",
    "x = sm.add_constant(temp[:, :-1]) # 线性回归增加常数项 y=kx+b\n",
    "y = temp[:, -1]\n",
    "regr = sm.OLS(y, x) # 普通最小二乘模型，ordinary least square model\n",
    "res = regr.fit()    #res.model.endog\n",
    "# 从模型获得拟合数据\n",
    "print(res.summary())\n",
    "st, data, ss2 = summary_table(res, alpha=0.05) # 置信水平alpha=5%，st数据汇总，data数据详情，ss2数据列名\n",
    "fitted_values = data[:,2]  #等价于res.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dimensional-advocacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.00      0.00      0.00      1006\n",
      "         pos       0.87      1.00      0.93      6632\n",
      "\n",
      "    accuracy                           0.87      7638\n",
      "   macro avg       0.43      0.50      0.46      7638\n",
      "weighted avg       0.75      0.87      0.81      7638\n",
      "\n",
      "average precision: 0.8686567164179104\n",
      "time spent: 2.3886771202087402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/guhaiqiao/anaconda3/envs/LM/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pylab\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def plot_pr(auc_score, precision, recall, label=None):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    pylab.xlim([0.0, 1.0])\n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('Recall')\n",
    "    pylab.ylabel('Precision')\n",
    "    pylab.title('P/R (AUC=%0.2f) / %s' % (auc_score, label))\n",
    "    pylab.fill_between(recall, precision, alpha=0.5)\n",
    "    pylab.grid(True, linestyle='-', color='0.75')\n",
    "    pylab.plot(recall, precision, lw=1)\n",
    "    pylab.show()\n",
    "\n",
    "start_time = time.time()\n",
    "# temp = np.c_[index1, index2, index7, index8, f]\n",
    "temp = np.c_[index1, index2, f]\n",
    "x = temp[(temp[:, 0] > 0)]\n",
    "print(len(x))\n",
    "# print(temp[:10])\n",
    "\n",
    "average = 0\n",
    "testNum = 50\n",
    "for i in range(0, testNum):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(x[:, :2], x[:, 3],\n",
    "#                                                     test_size=0.2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x[:, 1:-1], x[:, -1],\n",
    "                                                    test_size=0.2)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    p = np.mean(y_pred == y_test)\n",
    "    average += p\n",
    "\n",
    "answer = lr.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, answer)\n",
    "report = answer > 0.5\n",
    "print(classification_report(y_test, report, target_names=['neg', 'pos']))\n",
    "print(\"average precision:\", average / testNum)\n",
    "print(\"time spent:\", time.time() - start_time)\n",
    "plot_pr(0.5, precision, recall, \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[np.nan], [1], [2]])\n",
    "a = np.append(a, [1, 2, 3])\n",
    "print(a[:-1])\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datautil\n",
    "import pandas as pd\n",
    "dep_change = datautil.select_dependency_changes_all()\n",
    "dep_change.to_csv('data/migration_changes.csv')\n",
    "print(len(dep_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import numpy as np\n",
    "lib = \"org.json:json\"\n",
    "migrations_to_lib = model.get_migration_to_library(lib).values\n",
    "migrations_from_lib = model.get_migration_from_library(lib).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = np.array([])\n",
    "index2 = np.array([])\n",
    "index7 = np.array([])\n",
    "index8 = np.array([])\n",
    "f = np.array([])\n",
    "\n",
    "for migration in migrations_to_lib:\n",
    "    index1 = np.append(index1, model.index_1(migration, lib))\n",
    "    index2 = np.append(index2, model.index_2(migration, lib))\n",
    "    index7 = np.append(index7, model.get_library_retention_rate(migration, lib))\n",
    "    index8 = np.append(index8, model.get_library_inflow_rate(migration, lib))\n",
    "    f = np.append(f, 1)\n",
    "for migration in migrations_from_lib:\n",
    "    index1 = np.append(index1, model.index_1(migration, lib))\n",
    "    index2 = np.append(index2, model.index_2(migration, lib))\n",
    "    f = np.append(f, 0)\n",
    "\n",
    "print(len(index1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pylab\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def plot_pr(auc_score, precision, recall, label=None):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    pylab.xlim([0.0, 1.0])\n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('Recall')\n",
    "    pylab.ylabel('Precision')\n",
    "    pylab.title('P/R (AUC=%0.2f) / %s' % (auc_score, label))\n",
    "    pylab.fill_between(recall, precision, alpha=0.5)\n",
    "    pylab.grid(True, linestyle='-', color='0.75')\n",
    "    pylab.plot(recall, precision, lw=1)\n",
    "    pylab.show()\n",
    "\n",
    "start_time = time.time()\n",
    "x = np.c_[index1, index2]\n",
    "# x = index2.reshape(-1, 1)\n",
    "\n",
    "average = 0\n",
    "testNum = 10\n",
    "for i in range(0, testNum):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, f,\n",
    "                                                    test_size=0.2)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    p = np.mean(y_pred == y_test)\n",
    "    print(p)\n",
    "    average += p\n",
    "\n",
    "answer = lr.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, answer)\n",
    "report = answer > 0.5\n",
    "print(classification_report(y_test, report, target_names=['neg', 'pos']))\n",
    "print(\"average precision:\", average / testNum)\n",
    "print(\"time spent:\", time.time() - start_time)\n",
    "plot_pr(0.5, precision, recall, \"pos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
