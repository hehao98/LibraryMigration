{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "appreciated-dictionary",
   "metadata": {},
   "source": [
    "# Predictive Modeling for Library Migration\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "* H1: If many other projects have removed a library, it will be more likely for a project to migrate away from this library\n",
    "* H2: If many other projects have migrated from a library, it will be more likely for a project to migrate away from this library\n",
    "* H3: If the use of a library do not align well with current best practices, it will more likely for a project to migrate away from this library\n",
    "* H4: If a project have simultaneous use of same-domain libraries, it will be more likely to consolidate its usage to a single library\n",
    "* H5: A project is more likely to use a library that its upstream projects are already using\n",
    "* H6: If a library is not actively maintained, it will be more likely for a project to migrate away from this library\n",
    "* H7: If a library has unpatched security vulnerabilities, it will be more likely for a project to migrate away from this library\n",
    "* H8: If a library has an unusual license, it will be more likely for a project to migrate away from this library\n",
    "\n",
    "## Model\n",
    "\n",
    "首先，我们确立一组感兴趣的库集合$L$（$L$可能是若干个同一领域的库）。我们对这些库在大规模的项目集合$\\mathcal{P}$上提取所有的依赖项变更\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta L   &= \\{\\langle t,p,c,f,l^-,l^+,v^-,v^+ \\rangle\\}, p\\in \\mathcal{P}, x \\in \\Delta L \\Rightarrow x.l^- \\in L \\lor x.l^+ \\in L\\\\\n",
    "\\Delta L^+ &= \\{x | x \\in \\Delta L \\land x.l^+ \\in L \\land x.l^- = \\emptyset \\}\\\\\n",
    "\\Delta L^- &= \\{x | x \\in \\Delta L \\land x.l^- \\in L \\land x.l^+ = \\emptyset\\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "其中，$t$是时间，$c$是Commit，$f$是被修改的依赖配置文件。\n",
    "\n",
    "我们使用逻辑回归模型来拟合一个函数$f$，满足\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "f(x) = 1, x \\in \\Delta L^+ \\\\\n",
    "f(x) = 0, x \\in \\Delta L^-\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "对每个$x \\in \\Delta L$，定义其被添加或被删除的库为$l$，计算如下特征\n",
    "\n",
    "1. 项目做出变更的时间$t$减去$l$最近的上一次发布的时间。（刻画库是否正在被维护，验证H6）\n",
    "2. 项目做出变更的时间$t$减去$l$的第一次发布的时间。（刻画库的老旧程度，验证H6）\n",
    "3. 项目做出变更时，$l$能够查询到的安全漏洞的数量。（刻画库的安全漏洞情况，验证H7）\n",
    "4. $l$的许可证情况，按$L$集合里的许可证数量进行one-hot encoding。（验证H8）\n",
    "5. 项目做出变更时，项目的间接依赖里是否已经包含$l$。（验证H5）\n",
    "6. 项目做出变更时，项目的其他依赖配置文件里是否已经声明了$l$。(验证H4）\n",
    "7. 项目做出变更时，$l$在$\\mathcal{P}$中的全局留存率（1 - 被删除的次数 / 被添加的次数）。（验证H1）\n",
    "8. 项目做出变更时，$l$在已确认迁移中的流入比率（迁移图上入度 / 出度）。（验证H2）\n",
    "9. 项目做出变更时，$l$与剩下所有依赖的Pointwise Mutual Information (PMI)均值\n",
    "    $$\n",
    "    \\frac{1}{|x.f|}\\sum_{l'\\in x.f} \\log \\frac{p(l,l')}{p(l)p(l')}\n",
    "    $$\n",
    "    公式中概率使用$\\mathcal{P}$中所有依赖配置文件来估计。（验证H3）\n",
    "\n",
    "备注：为了计算上述指标，需要额外研究一下如何获取安全漏洞数据。可能考虑：GitHub Advisories，或参考已有研究。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datautil\n",
    "import pandas as pd\n",
    "dep_change = datautil.select_dependency_changes_all()\n",
    "dep_change.to_csv('data/migration_changes.csv')\n",
    "print(len(dep_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import numpy as np\n",
    "lib = \"org.json:json\"\n",
    "migrations_to_lib = model.get_migration_to_library(lib).values\n",
    "migrations_from_lib = model.get_migration_from_library(lib).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = np.array([])\n",
    "index2 = np.array([])\n",
    "index7 = np.array([])\n",
    "index8 = np.array([])\n",
    "f = np.array([])\n",
    "\n",
    "for migration in migrations_to_lib:\n",
    "    index1 = np.append(index1, model.index_1(migration, lib))\n",
    "    index2 = np.append(index2, model.index_2(migration, lib))\n",
    "    index7 = np.append(index7, model.get_library_retention_rate(migration, lib))\n",
    "    index8 = np.append(index8, model.get_library_inflow_rate(migration, lib))\n",
    "    f = np.append(f, 1)\n",
    "for migration in migrations_from_lib:\n",
    "    index1 = np.append(index1, model.index_1(migration, lib))\n",
    "    index2 = np.append(index2, model.index_2(migration, lib))\n",
    "    f = np.append(f, 0)\n",
    "\n",
    "print(len(index1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pylab\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def plot_pr(auc_score, precision, recall, label=None):\n",
    "    pylab.figure(num=None, figsize=(6, 5))\n",
    "    pylab.xlim([0.0, 1.0])\n",
    "    pylab.ylim([0.0, 1.0])\n",
    "    pylab.xlabel('Recall')\n",
    "    pylab.ylabel('Precision')\n",
    "    pylab.title('P/R (AUC=%0.2f) / %s' % (auc_score, label))\n",
    "    pylab.fill_between(recall, precision, alpha=0.5)\n",
    "    pylab.grid(True, linestyle='-', color='0.75')\n",
    "    pylab.plot(recall, precision, lw=1)\n",
    "    pylab.show()\n",
    "\n",
    "start_time = time.time()\n",
    "x = np.c_[index1, index2]\n",
    "# x = index2.reshape(-1, 1)\n",
    "\n",
    "average = 0\n",
    "testNum = 10\n",
    "for i in range(0, testNum):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, f,\n",
    "                                                    test_size=0.2)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    p = np.mean(y_pred == y_test)\n",
    "    print(p)\n",
    "    average += p\n",
    "\n",
    "answer = lr.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, answer)\n",
    "report = answer > 0.5\n",
    "print(classification_report(y_test, report, target_names=['neg', 'pos']))\n",
    "print(\"average precision:\", average / testNum)\n",
    "print(\"time spent:\", time.time() - start_time)\n",
    "plot_pr(0.5, precision, recall, \"pos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}